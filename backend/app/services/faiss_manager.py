"""
FAISS ç´¢å¼•ç®¡ç†å™¨

è´Ÿè´£æ„å»ºã€ä¿å­˜ã€åŠ è½½å’ŒæŸ¥è¯¢ FAISS ç´¢å¼•
"""

import faiss
import numpy as np
import json
import os
from typing import List, Tuple, Dict, Optional
from datetime import datetime
from zoneinfo import ZoneInfo


class FAISSManager:
    """
    FAISS ç´¢å¼•ç®¡ç†å™¨
    
    ç´¢å¼•ç±»å‹ï¼š
    - IndexFlatIP: å†…ç§¯ç›¸ä¼¼åº¦ï¼ˆé€‚åˆå½’ä¸€åŒ–å‘é‡ï¼‰
    - IndexFlatL2: L2 è·ç¦»
    - IndexIVFFlat: å€’æ’ç´¢å¼•ï¼ˆé€‚åˆå¤§è§„æ¨¡æ•°æ®ï¼‰
    """
    
    def __init__(
        self,
        embedding_dim: int = 512,
        index_path: str = "./data/index/products.index",
        metadata_path: str = "./data/index/products_metadata.json"
    ):
        """
        åˆå§‹åŒ– FAISS ç®¡ç†å™¨
        
        Args:
            embedding_dim: ç‰¹å¾ç»´åº¦
            index_path: ç´¢å¼•æ–‡ä»¶è·¯å¾„
            metadata_path: å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        """
        self.embedding_dim = embedding_dim
        self.index_path = index_path
        self.metadata_path = metadata_path
        
        # ç´¢å¼•å’Œå…ƒæ•°æ®
        self.index = None
        self.id_to_sku = []  # ç´¢å¼•ä½ç½® -> sku_id æ˜ å°„
        self.sku_to_ids = {}  # sku_id -> [ç´¢å¼•ä½ç½®åˆ—è¡¨] æ˜ å°„
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(index_path), exist_ok=True)
    
    def build_index(
        self,
        embeddings: np.ndarray,
        sku_ids: List[int],
        use_gpu: bool = False
    ):
        """
        æ„å»ºæ–°ç´¢å¼•
        
        Args:
            embeddings: ç‰¹å¾çŸ©é˜µ (N x D)
            sku_ids: å•†å“IDåˆ—è¡¨ (N,)
            use_gpu: æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿ
        """
        print(f"ğŸ”¨ æ„å»º FAISS ç´¢å¼•...")
        print(f"   æ ·æœ¬æ•°é‡: {len(embeddings)}")
        print(f"   ç‰¹å¾ç»´åº¦: {embeddings.shape[1]}")
        
        # åˆ›å»ºç´¢å¼•ï¼ˆä½¿ç”¨å†…ç§¯ç›¸ä¼¼åº¦ï¼Œé€‚åˆå½’ä¸€åŒ–å‘é‡ï¼‰
        self.index = faiss.IndexFlatIP(self.embedding_dim)
        
        # GPU åŠ é€Ÿï¼ˆå¯é€‰ï¼‰
        if use_gpu and faiss.get_num_gpus() > 0:
            print("ğŸš€ ä½¿ç”¨ GPU åŠ é€Ÿ")
            self.index = faiss.index_cpu_to_all_gpus(self.index)
        
        # æ·»åŠ å‘é‡
        self.index.add(embeddings)
        
        # æ„å»ºæ˜ å°„å…³ç³»
        self.id_to_sku = sku_ids.tolist()
        self._build_sku_mapping()
        
        print(f"âœ… ç´¢å¼•æ„å»ºå®Œæˆï¼ŒåŒ…å« {self.index.ntotal} ä¸ªå‘é‡")
    
    def _build_sku_mapping(self):
        """æ„å»º sku_id -> ç´¢å¼•ä½ç½® çš„æ˜ å°„"""
        self.sku_to_ids = {}
        for idx, sku_id in enumerate(self.id_to_sku):
            if sku_id not in self.sku_to_ids:
                self.sku_to_ids[sku_id] = []
            self.sku_to_ids[sku_id].append(idx)
    
    def add_vectors(
        self,
        embeddings: np.ndarray,
        sku_ids: List[int]
    ):
        """
        å¢é‡æ·»åŠ å‘é‡ï¼ˆç”¨äºåœ¨çº¿æ›´æ–°ï¼‰
        
        Args:
            embeddings: æ–°å¢ç‰¹å¾çŸ©é˜µ
            sku_ids: å¯¹åº”çš„å•†å“IDåˆ—è¡¨
        """
        if self.index is None:
            raise ValueError("ç´¢å¼•æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ build_index")
        
        # æ·»åŠ å‘é‡
        self.index.add(embeddings)
        
        # æ›´æ–°æ˜ å°„
        self.id_to_sku.extend(sku_ids)
        self._build_sku_mapping()
        
        print(f"âœ… å¢é‡æ·»åŠ  {len(embeddings)} ä¸ªå‘é‡ï¼Œå½“å‰æ€»æ•°: {self.index.ntotal}")
    
    def search(
        self,
        query_embedding: np.ndarray,
        top_k: int = 5,
        return_scores: bool = True
    ) -> List[Tuple[int, float]]:
        """
        æœç´¢æœ€ç›¸ä¼¼çš„å•†å“
        
        Args:
            query_embedding: æŸ¥è¯¢å‘é‡ (D,)
            top_k: è¿”å›å‰ K ä¸ªç»“æœ
            return_scores: æ˜¯å¦è¿”å›ç›¸ä¼¼åº¦åˆ†æ•°
            
        Returns:
            [(sku_id, score), ...] åˆ—è¡¨
        """
        if self.index is None:
            raise ValueError("ç´¢å¼•æœªåŠ è½½ï¼Œè¯·å…ˆåŠ è½½æˆ–æ„å»ºç´¢å¼•")
        
        # ç¡®ä¿æ˜¯ 2D æ•°ç»„
        if query_embedding.ndim == 1:
            query_embedding = query_embedding.reshape(1, -1)
        
        # æœç´¢
        scores, indices = self.index.search(query_embedding, top_k * 2)  # å¤šæœç´¢ä¸€äº›ï¼Œç”¨äºå»é‡
        
        # å»é‡ï¼ˆåŒä¸€å•†å“åªä¿ç•™æœ€é«˜åˆ†çš„ï¼‰
        results = []
        seen_skus = set()
        
        for score, idx in zip(scores[0], indices[0]):
            if idx < 0 or idx >= len(self.id_to_sku):
                continue
            
            sku_id = self.id_to_sku[idx]
            
            if sku_id not in seen_skus:
                seen_skus.add(sku_id)
                results.append((sku_id, float(score)))
            
            if len(results) >= top_k:
                break
        
        return results
    
    def search_with_aggregation(
        self,
        query_embedding: np.ndarray,
        top_k: int = 5,
        aggregation: str = "max"
    ) -> List[Tuple[int, float]]:
        """
        æœç´¢å¹¶èšåˆåŒä¸€å•†å“çš„å¤šä¸ªæ ·æœ¬åˆ†æ•°
        
        Args:
            query_embedding: æŸ¥è¯¢å‘é‡
            top_k: è¿”å›å‰ K ä¸ªå•†å“
            aggregation: èšåˆæ–¹å¼ (max/mean/sum)
            
        Returns:
            [(sku_id, score), ...] åˆ—è¡¨
        """
        if self.index is None:
            raise ValueError("ç´¢å¼•æœªåŠ è½½")
        
        # ç¡®ä¿æ˜¯ 2D æ•°ç»„
        if query_embedding.ndim == 1:
            query_embedding = query_embedding.reshape(1, -1)
        
        # æœç´¢æ‰€æœ‰å‘é‡
        num_samples = min(self.index.ntotal, top_k * 10)
        scores, indices = self.index.search(query_embedding, num_samples)
        
        # æŒ‰ sku_id èšåˆåˆ†æ•°
        sku_scores = {}
        for score, idx in zip(scores[0], indices[0]):
            if idx < 0 or idx >= len(self.id_to_sku):
                continue
            
            sku_id = self.id_to_sku[idx]
            
            if sku_id not in sku_scores:
                sku_scores[sku_id] = []
            sku_scores[sku_id].append(float(score))
        
        # èšåˆ
        results = []
        for sku_id, scores_list in sku_scores.items():
            if aggregation == "max":
                agg_score = max(scores_list)
            elif aggregation == "mean":
                agg_score = np.mean(scores_list)
            elif aggregation == "sum":
                agg_score = sum(scores_list)
            else:
                agg_score = max(scores_list)
            
            results.append((sku_id, agg_score))
        
        # æ’åºå¹¶è¿”å› top-k
        results.sort(key=lambda x: x[1], reverse=True)
        return results[:top_k]
    
    def save(self):
        """ä¿å­˜ç´¢å¼•å’Œå…ƒæ•°æ®åˆ°ç£ç›˜"""
        if self.index is None:
            raise ValueError("ç´¢å¼•æœªåˆå§‹åŒ–")
        
        print(f"ğŸ’¾ ä¿å­˜ç´¢å¼•åˆ° {self.index_path}")
        
        # ä¿å­˜ FAISS ç´¢å¼•
        faiss.write_index(self.index, self.index_path)
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata = {
            "embedding_dim": self.embedding_dim,
            "num_vectors": self.index.ntotal,
            "id_to_sku": self.id_to_sku,
            "sku_to_ids": self.sku_to_ids,
            "created_at": datetime.now(ZoneInfo("Asia/Shanghai")).isoformat(),
            "version": "1.0"
        }
        
        with open(self.metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç´¢å¼•å·²ä¿å­˜ï¼ŒåŒ…å« {self.index.ntotal} ä¸ªå‘é‡")
    
    def load(self):
        """ä»ç£ç›˜åŠ è½½ç´¢å¼•å’Œå…ƒæ•°æ®"""
        if not os.path.exists(self.index_path):
            raise FileNotFoundError(f"ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {self.index_path}")
        
        print(f"ğŸ“‚ åŠ è½½ç´¢å¼•: {self.index_path}")
        
        # åŠ è½½ FAISS ç´¢å¼•
        self.index = faiss.read_index(self.index_path)
        
        # åŠ è½½å…ƒæ•°æ®
        with open(self.metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        self.id_to_sku = metadata["id_to_sku"]
        self.sku_to_ids = {int(k): v for k, v in metadata["sku_to_ids"].items()}
        
        print(f"âœ… ç´¢å¼•å·²åŠ è½½ï¼ŒåŒ…å« {self.index.ntotal} ä¸ªå‘é‡")
        print(f"   åˆ›å»ºæ—¶é—´: {metadata.get('created_at', 'unknown')}")
    
    def get_stats(self) -> Dict:
        """è·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯"""
        if self.index is None:
            return {"status": "not_loaded"}
        
        num_skus = len(self.sku_to_ids)
        avg_samples_per_sku = self.index.ntotal / num_skus if num_skus > 0 else 0
        
        return {
            "status": "loaded",
            "num_vectors": self.index.ntotal,
            "num_skus": num_skus,
            "avg_samples_per_sku": round(avg_samples_per_sku, 2),
            "embedding_dim": self.embedding_dim
        }


# å…¨å±€å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
_faiss_manager = None


def get_faiss_manager(embedding_dim: int = 512) -> FAISSManager:
    """è·å–å…¨å±€ FAISS ç®¡ç†å™¨å®ä¾‹"""
    global _faiss_manager
    if _faiss_manager is None:
        _faiss_manager = FAISSManager(embedding_dim=embedding_dim)
    return _faiss_manager

